[{"name":"app.R","content":"# app.R — CLT / LLN Intuition Simulator (single-file; Shiny + bslib v5)\nlibrary(shiny)\nlibrary(bslib)\nlibrary(ggplot2)\n\n'\nunlink(\"docs\", recursive = TRUE, force = TRUE)\nshinylive::export(appdir = \".\", destdir = \"docs\")\nhttpuv::runStaticServer(\"docs\", port = 8000)\n'\n\n\nif (FALSE) {\n  library(munsell)\n  library(tibble)\n  #library(tidyverse)\n}\n\n\n\nCLT_VH <- \"calc(100vh - 120px)\"\n`%||%` <- function(a, b) if (is.null(a)) b else a\n\n# =========================\n# Color system (edit here)\n# =========================\nCOL_BG       <- \"#f7f6f3\"\nCOL_BARS     <- \"#4A4E69\"   # dot/hist fill color\nCOL_OUTLINE  <- COL_BG      # minimal outlines; set darker if desired\nCOL_EXPECTED <- \"#E69F00\"   # expected distribution curve (orange)\nCOL_CENTER   <- \"#2f6f8f\"   # center vertical line (cyan-leaning blue; high contrast vs COL_BARS)\n\n# =========================\n# Plot theme\n# =========================\nPlot_theme <- function(\n    base_font    = c(\"Avenir Next\", \"Verdana\", \"sans-serif\"),\n    heading_font = c(\"Trebuchet MS\", \"Avenir\", \"Verdana\", \"sans-serif\"),\n    base_size = 14\n) {\n  base_family    <- base_font[[1]]\n  heading_family <- heading_font[[1]]\n\n  theme_minimal(base_size = base_size, base_family = base_family) %+replace% theme(\n    plot.background  = element_rect(fill = COL_BG, color = NA),\n    panel.background = element_rect(fill = COL_BG, color = NA),\n\n    text = element_text(color = \"#343A40\"),\n\n    panel.grid.major = element_line(color = \"#cfdceb\", linewidth = 0.45),\n    panel.grid.minor = element_line(color = \"#e3edf7\", linewidth = 0.25),\n\n    axis.line = element_line(color = \"#9fb3c1\"),\n    axis.text.x  = element_text(color = \"#343A40\", family = base_family, size = 13),\n    axis.text.y  = element_text(color = \"#343A40\", family = base_family, size = 13),\n    axis.title.x = element_text(color = \"#343A40\", family = heading_family, face = \"bold\", size = 14),\n    axis.title.y = element_text(color = \"#343A40\", family = heading_family, face = \"bold\", size = 14, angle = 90, margin = margin(r = 3)),\n\n    plot.title = element_text(\n      family = heading_family, size = 16, face = \"bold\",\n      color = \"#2f3e46\", margin = margin(b = 8, unit = \"pt\")\n    ),\n    plot.subtitle = element_text(family = base_family, size = 12, color = \"#3b4a55\"),\n\n    plot.margin = margin(t = 5, r = 6, b = 4, l = 6, unit = \"pt\")\n  )\n}\n\n# =========================\n# Distributions\n# =========================\ndist_specs <- function(dist, params) {\n  if (dist == \"Normal\") {\n    mu <- params$mu; sd <- params$sd\n    gen <- function(n) rnorm(n, mean = mu, sd = sd)\n    return(list(name = \"Normal\", pop_center = mu, pop_sd = sd, gen = gen))\n  }\n  if (dist == \"Uniform\") {\n    a <- params$a; b <- params$b\n    gen <- function(n) runif(n, min = a, max = b)\n    pop_center <- (a + b) / 2\n    pop_sd <- (b - a) / sqrt(12)\n    return(list(name = \"Uniform\", pop_center = pop_center, pop_sd = pop_sd, gen = gen))\n  }\n  if (dist == \"Exponential\") {\n    mean <- params$exp_mean\n    rate <- 1 / mean\n    gen <- function(n) rexp(n, rate = rate)\n    pop_center <- mean\n    pop_sd <- mean\n    return(list(name = \"Exponential\", pop_center = pop_center, pop_sd = pop_sd, gen = gen))\n  }\n  if (dist == \"Lognormal\") {\n    median <- params$ln_median\n    sigma  <- params$ln_sigma\n    mu <- log(median) # median = exp(mu)\n    gen <- function(n) rlnorm(n, meanlog = mu, sdlog = sigma)\n    pop_center <- exp(mu + 0.5 * sigma^2) # mean for a consistent \"center\" anchor\n    pop_sd <- sqrt((exp(sigma^2) - 1) * exp(2 * mu + sigma^2))\n    return(list(name = \"Lognormal\", pop_center = pop_center, pop_sd = pop_sd, gen = gen))\n  }\n  if (dist == \"Bernoulli\") {\n    p <- params$p\n    gen <- function(n) rbinom(n, size = 1, prob = p)\n    pop_center <- p\n    pop_sd <- sqrt(p * (1 - p))\n    return(list(name = \"Bernoulli (0/1)\", pop_center = pop_center, pop_sd = pop_sd, gen = gen))\n  }\n  if (dist == \"Poisson\") {\n    lambda <- params$lambda\n    gen <- function(n) rpois(n, lambda = lambda)\n    pop_center <- lambda\n    pop_sd <- sqrt(lambda)\n    return(list(name = \"Poisson\", pop_center = pop_center, pop_sd = pop_sd, gen = gen))\n  }\n  stop(\"Unknown distribution\")\n}\n\ncalc_stat <- function(x, stat) if (stat == \"mean\") mean(x) else median(x)\npretty_stat <- function(stat) if (stat == \"mean\") \"Average\" else \"Median\"\n\n# =========================\n# Helpers: dot stacking + expected curve in counts\n# =========================\n\n# Compute stacked dot positions so y-axis truly represents Count\nstack_dots <- function(values, lim, bins) {\n  bw <- (lim[2] - lim[1]) / bins\n  if (!is.finite(bw) || bw <= 0) return(data.frame(x = numeric(0), y = integer(0)))\n\n  # Keep only finite values in-range\n  v <- values[is.finite(values) & values >= lim[1] & values <= lim[2]]\n  if (!length(v)) return(data.frame(x = numeric(0), y = integer(0)))\n\n  # Integer bin id: 0...(bins-1)\n  bin <- floor((v - lim[1]) / bw)\n  bin <- pmin(pmax(bin, 0), bins - 1)\n\n  # Bin center x-position\n  x_center <- lim[1] + (bin + 0.5) * bw\n\n  d <- data.frame(bin = bin, x = x_center)\n  d <- d[order(d$bin), , drop = FALSE]\n\n  # Stack within each bin (start at 0 so bottom dot sits on baseline)\n  d$y <- ave(d$bin, d$bin, FUN = function(z) seq_along(z) - 1)\n\n  d[, c(\"x\", \"y\")]\n}\n\n# Expected curve scaled to counts for continuous-ish distributions using a reference draw\nexpected_curve_counts_continuous <- function(ref, N, binwidth, from, to) {\n  ref <- ref[is.finite(ref)]\n  ref <- ref[ref >= 0]\n\n  # If nothing to estimate from, bail safely\n  if (length(ref) < 50 || !is.finite(N) || N <= 0 || !is.finite(binwidth) || binwidth <= 0) {\n    return(data.frame(x = numeric(0), y = numeric(0)))\n  }\n\n  # density always returns n points, but guard anyway\n  d <- density(ref, from = from, to = to, n = 512)\n  y <- d$y * N * binwidth\n\n  # If the curve is effectively zero everywhere, return empty (prevents invisible lines)\n  if (!any(is.finite(y)) || max(y, na.rm = TRUE) <= 0) {\n    return(data.frame(x = numeric(0), y = numeric(0)))\n  }\n\n  data.frame(x = d$x, y = y)\n}\n\n# Expected curve for discrete distributions (Poisson / Bernoulli) scaled to counts\nexpected_curve_counts_discrete <- function(dist, params, N, lim) {\n  if (!is.finite(N) || N <= 0) return(data.frame(x = numeric(0), y = numeric(0)))\n\n  if (dist == \"Poisson\") {\n    lam <- params$lambda\n    xs <- 0:floor(lim[2])\n    ys <- dpois(xs, lam) * N\n    return(data.frame(x = xs, y = ys))\n  }\n\n  if (dist == \"Bernoulli\") {\n    p <- params$p\n    xs <- c(0, 1)\n    ys <- dbinom(xs, 1, p) * N\n    return(data.frame(x = xs, y = ys))\n  }\n\n  data.frame(x = numeric(0), y = numeric(0))\n}\n\n# =========================\n# UI\n# =========================\nui <- page_navbar(\n  title = \"Intuition Lab\",\n  theme = bs_theme(\n    version = 5,\n    bg        = COL_BG,\n    fg        = \"#343A40\",\n    primary   = \"#2f6f8f\",\n    secondary = \"#495057\",\n    info      = \"#2f6f8f\"\n  ),\n\n  nav_panel(\n    \"CLT Visualizer\",\n    layout_sidebar(\n      sidebar = sidebar(\n        title = \"Central Limit Theorem (CLT)\",\n        open = \"open\",\n        width = 520,\n\n        p(strong(\"What this visualization shows\")),\n        p(\"The top row shows two independent samples drawn from the same process. The middle plot pools all raw points to reveal the underlying shape. The bottom plot pools the averages (or medians) from each sample—this is the CLT view, showing how the summary tightens and becomes more bell-shaped as sample size grows.\"),\n\n        p(strong(\"What it is\")),\n        p(\"The central limit theorem describes how averages behave across repeated sampling. Even when the raw data are skewed or irregular, the distribution of sample averages tends to become approximately bell-shaped when the sample size is large enough, and those averages cluster around the true center.\"),\n\n        p(strong(\"Why it matters\")),\n        p(\"In practice, people summarize data using averages: average risk, average cost, average change, and average differences between groups. The CLT explains why these averages become reliable as data accumulate and why uncertainty around them often follows predictable patterns, even when the raw data are not bell-shaped.\"),\n\n        p(strong(\"Common pitfalls\")),\n        p(\"Small samples can look unusual by chance, so one sample should not be treated as the full truth. The CLT is about averages (or other summaries), not raw values becoming bell-shaped. A common guideline is that n ≈ 30 is often 'enough,' but it is not definitive—the required sample size depends on skew, variability, and tail heaviness.\")\n      ),\n\n      layout_columns(\n        col_widths = c(4, 8),\n\n        # Controls\n        card(\n          height = CLT_VH,\n          card_header(\"Controls\"),\n          card_body(\n            selectInput(\n              \"clt_dist\",\n              \"Choose a source distribution\",\n              choices = c(\"Normal\", \"Uniform\", \"Exponential\", \"Lognormal\", \"Bernoulli\", \"Poisson\"),\n              selected = \"Normal\"\n            ),\n            uiOutput(\"clt_param_ui\"),\n\n            sliderInput(\"clt_n\", \"Sample size per draw\", min = 5, max = 500, value = 30, step = 5),\n\n            radioButtons(\n              \"clt_stat\",\n              \"Statistic to collect (bottom plot)\",\n              choices = c(\"Average\" = \"mean\", \"Median\" = \"median\"),\n              selected = \"mean\",\n              inline = TRUE\n            ),\n\n            hr(),\n\n            div(\n              style = \"display:flex; gap:10px; flex-wrap:wrap;\",\n              actionButton(\"clt_draw_once\", \"Draw once\", class = \"btn-primary\"),\n              actionButton(\"clt_reset\", \"Reset collectors\", class = \"btn-outline-secondary\")\n            ),\n\n            br(),\n\n            sliderInput(\"clt_runs\", \"Auto-run (number of draws)\", min = 10, max = 2000, value = 200, step = 25),\n            actionButton(\"clt_autorun\", \"Auto-run\", class = \"btn-outline-primary\"),\n\n            p(strong(\"Tip\")),\n            p(\"Try Exponential or Lognormal, then increase sample size and watch the bottom plot tighten even though the raw data stay skewed.\")\n          )\n        ),\n\n        # Plots\n        card(\n          height = CLT_VH,\n          full_screen = TRUE,\n          card_header(\"Plots\"),\n          card_body(\n            card(\n              card_header(\"Two independent samples (A and B)\"),\n              card_body(\n                layout_columns(\n                  col_widths = c(6, 6),\n                  plotOutput(\"clt_plot_A\", height = \"280px\"),\n                  plotOutput(\"clt_plot_B\", height = \"280px\")\n                )\n              )\n            ),\n\n            card(\n              card_header(\"Collector 1: all raw sample points pooled\"),\n              card_body(plotOutput(\"clt_plot_points\", height = \"240px\"))\n            ),\n\n            card(\n              full_screen = TRUE,\n              card_header(\"Collector 2: distribution of sample averages (CLT view)\"),\n              card_body(plotOutput(\"clt_plot_stats\", height = \"240px\"))\n            )\n          )\n        )\n      )\n    )\n  ),\n\n  nav_panel(\n    \"Acknowledgments\",\n    card(\n      card_body(\n        p(strong(\"Funding and Disclaimer\")),\n        p(\"This project is supported by the Assistant Secretary for Technology Policy (ASTP) of the US Department of Health and Human Services (HHS) under grant number 90PH0005/01-13.\"),\n        p(\"This information or content and conclusions are those of the authors and should not be construed as the official position or policy of, nor should any endorsements be inferred by ASTP, HHS or the U.S. Government.\")\n      )\n    )\n  )\n)\n\n# =========================\n# Server\n# =========================\nserver <- function(input, output, session) {\n\n  output$clt_param_ui <- renderUI({\n    dist <- input$clt_dist\n\n    if (dist == \"Normal\") {\n      tagList(\n        sliderInput(\"clt_mu\", \"Center (mean)\", min = 0, max = 50, value = 25, step = 1),\n        sliderInput(\"clt_sd\", \"Spread (sd)\",   min = 0.5, max = 25, value = 8, step = 0.5)\n      )\n    } else if (dist == \"Uniform\") {\n      tagList(\n        sliderInput(\"clt_a\", \"Minimum\", min = 0, max = 49, value = 0, step = 1),\n        sliderInput(\"clt_b\", \"Maximum\", min = 1, max = 100, value = 50, step = 1)\n      )\n    } else if (dist == \"Exponential\") {\n      sliderInput(\"clt_exp_mean\", \"Typical size (mean)\", min = 0.2, max = 30, value = 10, step = 0.2)\n    } else if (dist == \"Lognormal\") {\n      tagList(\n        sliderInput(\"clt_ln_median\", \"Typical value (median)\", min = 0.2, max = 30, value = 8, step = 0.2),\n        sliderInput(\"clt_ln_sigma\",  \"Skew / spread\",          min = 0.1, max = 2.0, value = 0.8, step = 0.05)\n      )\n    } else if (dist == \"Bernoulli\") {\n      sliderInput(\"clt_p\", \"Chance of 1\", min = 0.01, max = 0.99, value = 0.30, step = 0.01)\n    } else if (dist == \"Poisson\") {\n      sliderInput(\"clt_lambda\", \"Average rate (lambda)\", min = 0.5, max = 50, value = 6, step = 0.5)\n    }\n  })\n\n  params <- reactive({\n    list(\n      mu = input$clt_mu %||% 25,\n      sd = input$clt_sd %||% 8,\n      a  = input$clt_a  %||% 0,\n      b  = input$clt_b  %||% 50,\n      exp_mean  = input$clt_exp_mean %||% 10,\n      ln_median = input$clt_ln_median %||% 8,\n      ln_sigma  = input$clt_ln_sigma  %||% 0.8,\n      p = input$clt_p %||% 0.3,\n      lambda = input$clt_lambda %||% 6\n    )\n  })\n\n  clt_spec <- reactive({\n    d <- input$clt_dist\n    pr <- params()\n    if (d == \"Uniform\" && pr$a >= pr$b) pr$b <- pr$a + 1\n    dist_specs(d, pr)\n  })\n\n  # Reference draw for expected curves (kept modest for ShinyLive performance)\n  ref_draw <- reactive({\n    spec <- clt_spec()\n    spec$gen(20000)\n  })\n\n  x_limits <- reactive({\n    x <- ref_draw()\n    x <- x[is.finite(x)]\n    x <- x[x >= 0]\n\n    base <- as.numeric(quantile(x, probs = 0.999, names = FALSE))\n\n    dist <- input$clt_dist\n\n    # distribution-specific widening\n    if (dist == \"Lognormal\" || dist == \"Exponential\") {\n      xmax <- base * 2.5\n    } else if (dist == \"Poisson\") {\n      xmax <- base + 10\n    } else {\n      xmax <- base * 1.6\n    }\n\n    xmax <- max(xmax, 50)\n    c(0, xmax)\n  })\n\n\n  rv <- reactiveValues(\n    sampA = NULL,\n    sampB = NULL,\n    pooled_points = numeric(0),\n    pooled_stats  = numeric(0)\n  )\n\n  draw_once <- function() {\n    spec <- clt_spec()\n    n <- input$clt_n\n    stat <- input$clt_stat\n\n    a <- spec$gen(n)\n    b <- spec$gen(n)\n\n    rv$sampA <- a\n    rv$sampB <- b\n\n    rv$pooled_points <- c(rv$pooled_points, a, b)\n    rv$pooled_stats  <- c(rv$pooled_stats, calc_stat(a, stat), calc_stat(b, stat))\n  }\n\n  observeEvent(input$clt_draw_once, { draw_once() })\n\n  observeEvent(input$clt_autorun, {\n    spec <- clt_spec()\n    n <- input$clt_n\n    stat <- input$clt_stat\n    runs <- input$clt_runs\n\n    new_points <- numeric(0)\n    new_stats  <- numeric(2 * runs)\n\n    for (i in seq_len(runs)) {\n      a <- spec$gen(n)\n      b <- spec$gen(n)\n\n      new_points <- c(new_points, a, b)\n      new_stats[2*i - 1] <- calc_stat(a, stat)\n      new_stats[2*i]     <- calc_stat(b, stat)\n\n      if (i == runs) {\n        rv$sampA <- a\n        rv$sampB <- b\n      }\n    }\n\n    rv$pooled_points <- c(rv$pooled_points, new_points)\n    rv$pooled_stats  <- c(rv$pooled_stats, new_stats)\n  })\n\n  observeEvent(input$clt_reset, {\n    rv$sampA <- NULL\n    rv$sampB <- NULL\n    rv$pooled_points <- numeric(0)\n    rv$pooled_stats  <- numeric(0)\n  })\n\n  # ---------- Plot builders ----------\n\n  build_expected_df <- function(N_in, binwidth, lim) {\n    d <- input$clt_dist\n    pr <- params()\n\n    if (d %in% c(\"Poisson\", \"Bernoulli\")) {\n      expected_curve_counts_discrete(d, pr, N_in, lim)\n    } else {\n      expected_curve_counts_continuous(ref_draw(), N_in, binwidth, lim[1], lim[2])\n    }\n  }\n\n  sample_plot <- function(x, label) {\n    validate(need(!is.null(x), \"Click “Draw once” to generate Sample A and Sample B.\"))\n\n    spec <- clt_spec()\n    lim  <- x_limits()\n\n    stat     <- input$clt_stat\n    stat_val <- calc_stat(x, stat)\n\n    vals <- x[is.finite(x) & x >= lim[1] & x <= lim[2]]\n    df   <- data.frame(value = vals)\n\n    bins     <- 20\n    binwidth <- (lim[2] - lim[1]) / bins\n    N_in     <- nrow(df)\n    if (N_in < 2) exp_df <- data.frame(x=numeric(0), y=numeric(0))\n\n\n    # Base dot plot\n    p_base <- ggplot(df, aes(value)) +\n      geom_dotplot(\n        binaxis    = \"x\",\n        stackdir   = \"up\",\n        method     = \"histodot\",\n        binwidth   = binwidth,\n        dotsize    = 0.7,\n        stackratio = 1,\n        fill  = COL_BARS,\n        color = COL_OUTLINE,\n        alpha = 0.8\n      ) +\n      scale_x_continuous(limits = lim) +\n      scale_y_continuous(NULL, breaks = NULL) +\n      Plot_theme() +\n      theme(axis.ticks.y = element_blank(),\n            axis.text.y  = element_blank())\n\n    # If no points in range, just return the dotplot + lines\n    if (N_in <= 0) {\n      return(\n        p_base +\n          geom_vline(xintercept = spec$pop_center, linetype = \"dashed\", linewidth = 1.5, color = COL_CENTER) +\n          geom_vline(xintercept = stat_val, linewidth = 1.0) +\n          labs(\n            title = label,\n            subtitle = \"Orange dotted = expected shape; blue dashed = typical center; solid = this sample’s statistic\",\n            x = \"Value\", y = NULL\n          )\n      )\n    }\n\n    # Expected curve in COUNT units (this is the one you already trust)\n    exp_raw <- build_expected_df(N_in, binwidth, lim)\n\n    # Rescale expected curve to dotplot's internal y-units (stack height)\n    dot_data <- ggplot_build(p_base)$data[[1]]\n    max_stack_y <- suppressWarnings(max(dot_data$y, na.rm = TRUE))\n    max_exp_y   <- suppressWarnings(max(exp_raw$y,  na.rm = TRUE))\n\n    if (!is.finite(max_stack_y) || max_stack_y <= 0 || !is.finite(max_exp_y) || max_exp_y <= 0) {\n      exp_df <- data.frame(x = numeric(0), y = numeric(0))\n    } else {\n      exp_df <- transform(exp_raw, y = y / max_exp_y * max_stack_y)\n    }\n\n    p_base +\n      geom_line(\n        data = exp_df, aes(x, y), inherit.aes = FALSE,\n        linetype = \"dotted\", linewidth = 1.6, color = COL_EXPECTED\n      ) +\n      geom_vline(xintercept = spec$pop_center, linetype = \"dashed\", linewidth = 1.5, color = COL_CENTER) +\n      geom_vline(xintercept = stat_val, linewidth = 1.0) +\n      labs(\n        title = label,\n        x = \"Value\", y = NULL\n      )\n  }\n\n  output$clt_plot_A <- renderPlot({ sample_plot(rv$sampA, \"Sample A\") })\n  output$clt_plot_B <- renderPlot({ sample_plot(rv$sampB, \"Sample B\") })\n\n  output$clt_plot_points <- renderPlot({\n    validate(need(length(rv$pooled_points) > 0, \"Draw some samples to pool raw points.\"))\n\n    spec <- clt_spec()\n    lim <- x_limits()\n\n    # Filter to plotted range BEFORE scaling expected curve\n    vals <- rv$pooled_points\n    vals <- vals[is.finite(vals) & vals >= lim[1] & vals <= lim[2]]\n    df <- data.frame(value = vals)\n\n    bins <- 45\n    binwidth <- (lim[2] - lim[1]) / bins\n    N_in <- nrow(df)\n\n    exp_df <- build_expected_df(N_in, binwidth, lim)\n\n    ggplot(df, aes(value)) +\n      geom_histogram(\n        bins = bins,\n        fill = COL_BARS,\n        color = COL_OUTLINE,\n        alpha = 0.6\n      ) +\n      geom_line(data = exp_df, aes(x, y), inherit.aes = FALSE,\n                linetype = \"dotted\", linewidth = 1.5, color = COL_EXPECTED) +\n      geom_vline(xintercept = spec$pop_center,\n                 linetype = \"dashed\", linewidth = 1.5, color = COL_CENTER) +\n      scale_x_continuous(limits = lim) +\n      labs(\n        title = sprintf(\"Pooled raw points (in-range points = %d)\", N_in),\n        subtitle = \"Orange dotted = expected shape; blue dashed = typical center; solid = this sample’s statistic\",\n        x = \"Value\", y = \"Count\"\n      ) +\n      Plot_theme()\n  })\n\n  output$clt_plot_stats <- renderPlot({\n    validate(need(length(rv$pooled_stats) > 0, \"Draw some samples to pool the statistic.\"))\n\n    spec <- clt_spec()\n    lim <- x_limits()\n    stat <- input$clt_stat\n\n    vals <- rv$pooled_stats\n    vals <- vals[is.finite(vals) & vals >= lim[1] & vals <= lim[2]]\n    df <- data.frame(stat = vals)\n\n    bins <- 45\n    binwidth <- (lim[2] - lim[1]) / bins\n    N_in <- nrow(df)\n\n    p <- ggplot(df, aes(stat)) +\n      geom_histogram(\n        bins = bins,\n        fill = COL_BARS,\n        color = COL_OUTLINE,\n        alpha = 0.6\n      ) +\n      geom_vline(xintercept = spec$pop_center,\n                 linetype = \"dashed\", linewidth = 1.5, color = COL_CENTER) +\n      scale_x_continuous(limits = lim) +\n      labs(\n        title = sprintf(\"Pooled %s values (in-range total = %d)\", tolower(pretty_stat(stat)), N_in),\n        subtitle = \"Same x-axis as raw data. The distribution tightens around the typical center as sample size increases.\",\n        x = pretty_stat(stat), y = \"Count\"\n      ) +\n      Plot_theme()\n\n    # CLT reference curve overlay for mean only (scaled to counts)\n    if (stat == \"mean\" && is.finite(spec$pop_sd) && spec$pop_sd > 0 && N_in > 0) {\n      se <- spec$pop_sd / sqrt(input$clt_n)\n      xs <- seq(lim[1], lim[2], length.out = 512)\n      ys <- dnorm(xs, mean = spec$pop_center, sd = se) * N_in * binwidth\n      ref <- data.frame(x = xs, y = ys)\n\n      p <- p + geom_line(\n        data = ref, aes(x, y), inherit.aes = FALSE,\n        linetype = \"dotted\", linewidth = 1.5, color = COL_EXPECTED\n      )\n    }\n\n    p\n  })\n}\n\nshinyApp(ui, server)\n","type":"text"},{"name":"CentralLimitApp.Rproj","content":"Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTeX: pdfLaTeX\n\nAutoAppendNewline: Yes\nStripTrailingWhitespace: Yes\n","type":"text"}]
